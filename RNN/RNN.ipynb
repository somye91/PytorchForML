{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f5bf8c-ef2e-410e-af74-b932655a9da7",
   "metadata": {},
   "source": [
    "### Download the novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8ec87b9-b217-4ac9-9f0b-d500eace6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://gutenberg.org/cache/epub/73489/pg73489.txt\"\n",
    "response=requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"book.txt\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "else:\n",
    "    print(\"File not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33526b94-4053-4ef7-b17a-2f4855e89790",
   "metadata": {},
   "source": [
    "### Determine Start and End index of the text\n",
    "#### Prepare an index_to_char and char_to_index dictionary that will come in handy later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20b018e6-60a7-4a79-a48c-21bc37db780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of novel: 192221 \n",
      "\n",
      "Distinct characters: ['\\n', ' ', '!', '(', ')', '*', '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '£', '½', 'é', '‘', '’', '“', '”'] \n",
      "\n",
      "Count of distinct characters: 86 \n",
      "\n",
      "192221\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '(', 4: ')', 5: '*', 6: '+', 7: ',', 8: '-', 9: '.', 10: '0', 11: '1', 12: '2', 13: '3', 14: '4', 15: '5', 16: '6', 17: '7', 18: '8', 19: '9', 20: ':', 21: ';', 22: '=', 23: '?', 24: 'A', 25: 'B', 26: 'C', 27: 'D', 28: 'E', 29: 'F', 30: 'G', 31: 'H', 32: 'I', 33: 'J', 34: 'K', 35: 'L', 36: 'M', 37: 'N', 38: 'O', 39: 'P', 40: 'Q', 41: 'R', 42: 'S', 43: 'T', 44: 'U', 45: 'V', 46: 'W', 47: 'Y', 48: 'Z', 49: '[', 50: ']', 51: '_', 52: 'a', 53: 'b', 54: 'c', 55: 'd', 56: 'e', 57: 'f', 58: 'g', 59: 'h', 60: 'i', 61: 'j', 62: 'k', 63: 'l', 64: 'm', 65: 'n', 66: 'o', 67: 'p', 68: 'q', 69: 'r', 70: 's', 71: 't', 72: 'u', 73: 'v', 74: 'w', 75: 'x', 76: 'y', 77: 'z', 78: '|', 79: '£', 80: '½', 81: 'é', 82: '‘', 83: '’', 84: '“', 85: '”'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"book.txt\",'r',encoding=\"utf8\") as fp:\n",
    "    text=fp.read()\n",
    "start_idx=text.index(\"Once upon a time there was a little girl named Anne Wilbraham\")\n",
    "end_idx=text.index(\"THE END\")\n",
    "text=text[start_idx:end_idx]\n",
    "char_set=sorted(set(text))  ## Set function will prepare a list of unique characters in `text`\n",
    "print(f\"Total length of novel: {len(text)} \\n\")\n",
    "print(f\"Distinct characters: {char_set} \\n\")\n",
    "print(f\"Count of distinct characters: {len(char_set)} \\n\")\n",
    "\n",
    "char_to_idx = { char:idx for idx,char  in enumerate(char_set) }\n",
    "idx_to_char = { idx:char for (char,idx)  in char_to_idx.items() }\n",
    "\n",
    "## Convert original text to integers\n",
    "text_encoded = [ char_to_idx[char] for char in text ]\n",
    "print(len(text_encoded))\n",
    "\n",
    "\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627a98d-4447-4670-8cd0-daf771e5f4c4",
   "metadata": {},
   "source": [
    "### Prepare a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0222d699-d2d3-4df7-8355-5dba9a18e24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200]) torch.Size([])\n",
      "tensor([38, 65, 54, 56,  1, 72, 67, 66, 65,  1, 52,  1, 71, 60, 64, 56,  1, 71,\n",
      "        59, 56, 69, 56,  1, 74, 52, 70,  1, 52,  1, 63, 60, 71, 71, 63, 56,  1,\n",
      "        58, 60, 69, 63,  1, 65, 52, 64, 56, 55,  1, 24, 65, 65, 56,  1, 46, 60,\n",
      "        63, 53, 69, 52, 59, 52, 64,  1, 25, 52, 76, 56, 70,  7,  0, 46, 60, 63,\n",
      "        53, 69, 52, 59, 52, 64,  1, 53, 56, 60, 65, 58,  1, 52, 57, 71, 56, 69,\n",
      "         1, 59, 56, 69,  1, 58, 69, 52, 65, 55, 57, 52, 71, 59, 56, 69,  1, 66,\n",
      "        65,  1, 71, 59, 56,  1, 64, 66, 71, 59, 56, 69, 83, 70,  1, 70, 60, 55,\n",
      "        56,  7,  1, 52,  1, 73, 56, 69, 76,  0, 54, 63, 56, 73, 56, 69,  1, 58,\n",
      "        56, 65, 71, 63, 56, 64, 52, 65,  1, 63, 60, 73, 60, 65, 58,  1, 52, 71,\n",
      "         1, 30, 69, 56, 52, 71,  1, 36, 52, 63, 73, 56, 69, 65,  7,  1, 52, 65,\n",
      "        55,  1, 74, 69, 60, 71, 60, 65, 58,  1, 53, 66, 66, 62, 70,  1, 66, 65,\n",
      "         1, 41]) \n",
      " tensor(66)\n",
      "Once upon a time there was a little girl named Anne Wilbraham Bayes,\n",
      "Wilbraham being after her grandfather on the mother’s side, a very\n",
      "clever gentleman living at Great Malvern, and writing books on R\n",
      "o\n",
      "192021\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class PrepareData(Dataset):\n",
    "#     def __init__(self,text_encoded, window_size=50):\n",
    "#         self.text_encoded = text_encoded\n",
    "#         self.window_size = window_size\n",
    "#         self.input, self.label=self.getdata()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.input)\n",
    "\n",
    "#     def __getitem__(self,idx):\n",
    "#         input=self.input[idx]\n",
    "#         label=self.label[idx]\n",
    "#         return torch.tensor(input).long(), torch.tensor(label)\n",
    "\n",
    "#     def getdata(self):\n",
    "#         input=[]\n",
    "#         label=[]\n",
    "#         for i in range(len(self.text_encoded) - self.window_size):\n",
    "#             input.append(self.text_encoded[i:i+self.window_size])\n",
    "#             label.append(self.text_encoded[i+self.window_size])\n",
    "#         return input,label\n",
    "\n",
    "# window_size=200\n",
    "# dataset=PrepareData(text_encoded, window_size=window_size)\n",
    "# for i,j in dataset:\n",
    "#     print(i.shape,j.shape)  ## 1 character output for every sequence of 50 letters(window_size)\n",
    "#     print(i, \"\\n\", j)\n",
    "#     print(\"\".join([idx_to_char[a.item()] for a in i]))   ##Print the first input(sequence)\n",
    "#     print(idx_to_char[j.item()])  ##Print the first label, i.e next character prediction\n",
    "#     break\n",
    "# print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ffe0eb09-d177-4073-86e2-ee9a32eaa48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50]) torch.Size([50])\n",
      "tensor([38, 65, 54, 56,  1, 72, 67, 66, 65,  1, 52,  1, 71, 60, 64, 56,  1, 71,\n",
      "        59, 56, 69, 56,  1, 74, 52, 70,  1, 52,  1, 63, 60, 71, 71, 63, 56,  1,\n",
      "        58, 60, 69, 63,  1, 65, 52, 64, 56, 55,  1, 24, 65, 65]) \n",
      " tensor([65, 54, 56,  1, 72, 67, 66, 65,  1, 52,  1, 71, 60, 64, 56,  1, 71, 59,\n",
      "        56, 69, 56,  1, 74, 52, 70,  1, 52,  1, 63, 60, 71, 71, 63, 56,  1, 58,\n",
      "        60, 69, 63,  1, 65, 52, 64, 56, 55,  1, 24, 65, 65, 56])\n",
      "Once upon a time there was a little girl named Ann\n",
      "nce upon a time there was a little girl named Anne\n",
      "192171\n"
     ]
    }
   ],
   "source": [
    "## Trying to preare dataloaded in a different way\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PrepareData(Dataset):\n",
    "    def __init__(self,text_encoded, window_size=50):\n",
    "        self.text_encoded = text_encoded\n",
    "        self.window_size = window_size\n",
    "        self.input, self.label=self.getdata()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        input=self.input[idx]\n",
    "        label=self.label[idx]\n",
    "        return torch.tensor(input).long(), torch.tensor(label)\n",
    "\n",
    "    def getdata(self):\n",
    "        input=[]\n",
    "        label=[]\n",
    "        for i in range(len(self.text_encoded) - self.window_size):\n",
    "            input.append(self.text_encoded[i:i+self.window_size])\n",
    "            label.append(self.text_encoded[i+1: i+self.window_size + 1])\n",
    "        return input,label\n",
    "\n",
    "window_size=50\n",
    "dataset=PrepareData(text_encoded, window_size=window_size)\n",
    "for i,j in dataset:\n",
    "    print(i.shape, j.shape)\n",
    "    print(i, \"\\n\", j)\n",
    "    print(\"\".join([idx_to_char[a.item()] for a in i]))   ##Print the first input(sequence)\n",
    "    print(\"\".join([idx_to_char[b.item()] for b in j]))  ##Print the first label, i.e next character prediction\n",
    "    break\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c4a5386d-3e12-460d-8dfd-9bc247b177c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50])\n",
      "torch.Size([32, 50])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "torch.manual_seed(42)\n",
    "seq_dl = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "vocab_size = len(char_set)\n",
    "\n",
    "i,l = next(iter(seq_dl))\n",
    "print(i.shape)\n",
    "print(l.shape)   ## 1 character output for every sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "03a9a31f-cf96-4874-94de-ee893336622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 86])\n",
      "torch.Size([2, 32, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,128) \n",
    "        self.lstm = nn.LSTM(128,256, num_layers=2, batch_first=True, dropout=0.5)  \n",
    "        self.linear = nn.Linear(256,vocab_size)\n",
    "\n",
    "    def forward(self,x, hidden=None):\n",
    "        embedded=self.embedding(x)\n",
    "        #print(embedded.shape)\n",
    "        output, (h_n, c_n) = self.lstm(embedded)\n",
    "        #print(output.shape)\n",
    "        output = output[:, -1, :] ## We only want the last timestep\n",
    "        #print(output.shape)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        #output = self.linear(output) #.reshape(output.size(0), -1)\n",
    "        return output,h_n\n",
    "input,label=next(iter(seq_dl))\n",
    "rnn=RNN(vocab_size)\n",
    "print(rnn(input)[0].shape)  #output\n",
    "print(rnn(input)[1].shape)  ## h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9cc1b0-95aa-410b-be2a-e591c9a3fc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Loss: 1.7255\n",
      "Generated text:\n",
      "and things and her bears of to her and the she was and the had the back the other and the time the rest the spunder was for the would rear a little be shoppend the and said the bang the time the but t\n",
      "\n",
      "\n",
      "Epoch [100], Loss: 1.7766\n",
      "Generated text:\n",
      "peed and the come a got the seet a could the see more all sear was of the give have and the rest the get and in the half a latter and the somethers and Alison and so a long all the was of the keek and\n",
      "\n",
      "\n",
      "Epoch [200], Loss: 1.6533\n",
      "Generated text:\n",
      "jother the tore the can I of was the took a boy there a like the was and so to but the put a looked sometherses with the cabelled a portambed a cold for and the tore and said the know broked a piught \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.005)\n",
    "\n",
    "rnn.train()\n",
    "# Training loop\n",
    "epochs=10000\n",
    "for epoch in range(epochs):\n",
    "    rnn.train()\n",
    "    loss=0\n",
    "    hidden=None\n",
    "    inputs,labels=next(iter(seq_dl))  ### Pick a random batch\n",
    "    #print(inputs.shape, labels.shape)\n",
    "    #for inputs, labels in seq_dl:\n",
    "\n",
    "    for i in range(window_size): \n",
    "        # Forward pass\n",
    "        outputs,hidden = rnn(inputs[:,:i+1],hidden)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss+=  criterion(outputs, labels[:,i])\n",
    "    loss/=window_size\n",
    "\n",
    "        # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    hidden=hidden.detach()\n",
    "\n",
    "\n",
    "    # Print average loss for this epoch\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch [{epoch}], Loss: {loss.item() :.4f}\")\n",
    "        seed=random.choice(string.ascii_letters) ## Get a random char\n",
    "        generate_next_characters(rnn, seed, char_to_idx, idx_to_char,temperature=0.5)\n",
    "        print(\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4e545234-8b79-4f6e-b887-d86f9cb768a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "It was always longer, but the carriage was now about his news.\n",
      "\n",
      "“Infirmary,” said Matilda.\n",
      "\n",
      "“Oh, do doll’s have a new house were also on his coccass them indoors. Pembroke knew that\n",
      "when he would do n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.distributions.categorical import Categorical\n",
    "def generate_next_characters(model, seed, char_to_index, index_to_char, max_length=200, temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Convert the seed to tensor\n",
    "        seed_tensor = torch.tensor([char_to_index[char] for char in seed], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "        # Initialize the hidden state\n",
    "        hidden = None\n",
    "\n",
    "        # Generate next characters\n",
    "        generated_text = seed\n",
    "        for i in range(max_length):\n",
    "            # Forward pass\n",
    "            output, hidden = model(seed_tensor,hidden)\n",
    "\n",
    "            # Sample the next character using temperature\n",
    "            #probabilities = torch.softmax(output.squeeze() / temperature, dim=0)\n",
    "            #next_index = torch.multinomial(probabilities, 1).item()\n",
    "            #output=torch.softmax(output,dim=1)\n",
    "            m = Categorical(logits=output/temperature)\n",
    "            next_index = m.sample().item()\n",
    "\n",
    "            # Convert the index to character\n",
    "            next_char = index_to_char[next_index]\n",
    "\n",
    "            # Append the next character to the generated text\n",
    "            generated_text += next_char\n",
    "\n",
    "            # Update the seed for the next iteration\n",
    "            #seed_tensor=seed_tensor[:,1:]\n",
    "            seed_tensor = torch.cat((seed_tensor,torch.tensor([[next_index]])), dim=1)\n",
    "            \n",
    "                    \n",
    "            # Break if the generated text exceeds max length or if the next character is a newline\n",
    "            #if next_char == '\\n' or len(generated_text) >= max_length:\n",
    "            if len(generated_text) >= max_length:\n",
    "                break\n",
    "\n",
    "    # Print the generated text\n",
    "    print(\"Generated text:\")\n",
    "    print(generated_text)\n",
    "    model.train()\n",
    "\n",
    "seed = \"I\"\n",
    "generate_next_characters(rnn, seed, char_to_idx, idx_to_char,temperature=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5102d-d876-4613-bd8d-07a081814c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
